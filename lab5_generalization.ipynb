{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/porterjenkins/byu-cs474/blob/master/lab5_generalization.ipynb)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttC8f3uOlC2C"
   },
   "source": [
    "# Lab 5: Measuring Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dPQqEicJlNGa"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "\n",
    "*   Understand how to accurately measure generalization performance of deep networks\n",
    "*   Gain intuition into the bias-variance trade-off and the double descent phenomenon\n",
    "*   Investigate properties of high dimensional spaces and better understand the ''curse of dimensionality''\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDJ1RdGomDHj"
   },
   "source": [
    "## Deliverable\n",
    "\n",
    "You will turn in a completed version of notebook to Canvas/Learning Suite.  In various places you will see the words \"TO DO\". Follow the instructions at these places and write code to complete the instructions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrGvYA4pkxH-"
   },
   "source": [
    "## Notes\n",
    "You will not need a GPU instance for this lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joIT4SFmmeFp"
   },
   "source": [
    "## Q1) Understanding Generalization\n",
    "\n",
    "In this question, we will use the MNIST1D dataset (https://github.com/greydanus/mnist1d) to reproduce Figure 8.2 from Prince."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cSu7e4Jmtfm"
   },
   "outputs": [],
   "source": [
    "# Run this if you're in a Colab to install MNIST 1D repository\n",
    "%pip install git+https://github.com/greydanus/mnist1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9387,
     "status": "ok",
     "timestamp": 1721938999131,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "3z76SO4ymxbW"
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mnist1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDJ27aiZnRa-"
   },
   "source": [
    "Let's generate a training and test dataset using the MNIST1D code. The dataset gets saved as a .pkl file so it doesn't have to be regenerated each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7271,
     "status": "ok",
     "timestamp": 1721939006399,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "Nh2VSEZHnSlo",
    "outputId": "dafa4a04-b658-456f-ca17-034d92d2fe1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples in training set: 4000\n",
      "Examples in test set: 1000\n",
      "Length of each example: 40\n"
     ]
    }
   ],
   "source": [
    "!mkdir ./sample_data\n",
    "\n",
    "args = mnist1d.data.get_dataset_args()\n",
    "data = mnist1d.data.get_dataset(args, path='./sample_data/mnist1d_data.pkl', download=False, regenerate=False)\n",
    "\n",
    "# The training and test input and outputs are in\n",
    "# data['x'], data['y'], data['x_test'], and data['y_test']\n",
    "print(\"Examples in training set: {}\".format(len(data['y'])))\n",
    "print(\"Examples in test set: {}\".format(len(data['y_test'])))\n",
    "print(\"Length of each example: {}\".format(data['x'].shape[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1721939006399,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "qFiZ1dY9nUcO"
   },
   "outputs": [],
   "source": [
    "D_i = 40    # Input dimensions\n",
    "D_k = 100   # Hidden dimensions\n",
    "D_o = 10    # Output dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpU3rh4KuPHv"
   },
   "source": [
    "### Part 1.a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gBmIfg5veT9S"
   },
   "source": [
    "**TODO:** Define a PyTorch model with two hidden layers of size 100 And ReLU activations between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 243,
     "status": "ok",
     "timestamp": 1721939006641,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "iPSyIAj0rDqA"
   },
   "outputs": [],
   "source": [
    "# Your code here (see Figure 7.8 of book for help)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lj_PwXFXekFA"
   },
   "source": [
    "**TODO:** Initialize the parameters with He initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1721939006641,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "S94b51qnoQU2"
   },
   "outputs": [],
   "source": [
    "def weights_init(layer_in):\n",
    "  # Replace this line (see figure 7.8 of Prince for help)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1721939006641,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "5Rf4hB4RoZpg",
    "outputId": "b8fcf526-1512-4dc6-d31e-e18f33f520f6"
   },
   "outputs": [],
   "source": [
    "# Call the function you just defined\n",
    "model.apply(weights_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12798,
     "status": "ok",
     "timestamp": 1721939019438,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "NbNIYtj7nZQj",
    "outputId": "dd22db91-07e5-41fb-cca8-9e94b9183cb8"
   },
   "outputs": [],
   "source": [
    "# choose cross entropy loss function (equation 5.24)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "# construct SGD optimizer and initialize learning rate and momentum\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.05, momentum=0.9)\n",
    "# object that decreases learning rate by half every 10 epochs\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "x_train = torch.tensor(data['x'].astype('float32'))\n",
    "y_train = torch.tensor(data['y'].transpose().astype('long'))\n",
    "x_test= torch.tensor(data['x_test'].astype('float32'))\n",
    "y_test = torch.tensor(data['y_test'].astype('long'))\n",
    "\n",
    "# load the data into a class that creates the batches\n",
    "data_loader = DataLoader(TensorDataset(x_train,y_train), batch_size=100, shuffle=True, worker_init_fn=np.random.seed(1))\n",
    "\n",
    "# Initialize model weights\n",
    "model.apply(weights_init)\n",
    "\n",
    "# loop over the dataset n_epoch times\n",
    "n_epoch = 50\n",
    "# store the loss and the % correct at each epoch\n",
    "losses_train = np.zeros((n_epoch))\n",
    "errors_train = np.zeros((n_epoch))\n",
    "losses_test = np.zeros((n_epoch))\n",
    "errors_test = np.zeros((n_epoch))\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "  # loop over batches\n",
    "  for i, batch in enumerate(data_loader):\n",
    "    # retrieve inputs and labels for this batch\n",
    "    x_batch, y_batch = batch\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "    # forward pass -- calculate model output\n",
    "    pred = model(x_batch)\n",
    "    # compute the loss\n",
    "    loss = loss_function(pred, y_batch)\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    # SGD update\n",
    "    optimizer.step()\n",
    "\n",
    "  # Run whole dataset to get statistics -- normally wouldn't do this\n",
    "  pred_train = model(x_train)\n",
    "  pred_test = model(x_test)\n",
    "  _, predicted_train_class = torch.max(pred_train.data, 1)\n",
    "  _, predicted_test_class = torch.max(pred_test.data, 1)\n",
    "  errors_train[epoch] = 100 - 100 * (predicted_train_class == y_train).float().sum() / len(y_train)\n",
    "  errors_test[epoch]= 100 - 100 * (predicted_test_class == y_test).float().sum() / len(y_test)\n",
    "  losses_train[epoch] = loss_function(pred_train, y_train).item()\n",
    "  losses_test[epoch]= loss_function(pred_test, y_test).item()\n",
    "  print(f'Epoch {epoch:5d}, train loss {losses_train[epoch]:.6f}, train error {errors_train[epoch]:3.2f},  test loss {losses_test[epoch]:.6f}, test error {errors_test[epoch]:3.2f}')\n",
    "\n",
    "  # tell scheduler to consider updating learning rate\n",
    "  scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "executionInfo": {
     "elapsed": 491,
     "status": "ok",
     "timestamp": 1721939019917,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "k_TzmBOVnlSL",
    "outputId": "f814cb44-a73e-440f-cdf1-0e2710316e02"
   },
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(errors_train,'r-',label='train')\n",
    "ax.plot(errors_test,'b-',label='test')\n",
    "ax.set_ylim(0,100); ax.set_xlim(0,n_epoch)\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Error')\n",
    "ax.set_title('TrainError %3.2f, Test Error %3.2f'%(errors_train[-1],errors_test[-1]))\n",
    "ax.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(losses_train,'r-',label='train')\n",
    "ax.plot(losses_test,'b-',label='test')\n",
    "ax.set_xlim(0,n_epoch)\n",
    "ax.set_xlabel('Epoch'); ax.set_ylabel('Loss')\n",
    "ax.set_title('Train loss %3.2f, Test loss %3.2f'%(losses_train[-1],losses_test[-1]))\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slNQbGY8uYiX"
   },
   "source": [
    "### Part 1.b)\n",
    "\n",
    "Now let's increase the capacity of our model to have five hidden layers and re-run our experiment. Pay attention to what happens to the train and test curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSPCfIoTvU4g"
   },
   "source": [
    "**TODO:**\n",
    "Define a model with five hidden layers of size 100\n",
    "and ReLU activations between them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1721939019917,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "gy2gTmeruiz7"
   },
   "outputs": [],
   "source": [
    "# Your code here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lx0MKjx3vbLs"
   },
   "source": [
    "**TODO**: Train the model using the same code as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLPELEolvnxS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rC3feLw5v7pd"
   },
   "source": [
    "**TODO**: Plot the results using the same code as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0QV9y79Mv-Fk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKPGfSmuwcbS"
   },
   "source": [
    "### Part 1.c)\n",
    "\n",
    "Let's run one last experiment, this time with a simple linear model with **NO** hidden layers. In this case we will decrease the capacity of the model. Again, pay attention to what happens to the train and test curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDOtAsSYwtD2"
   },
   "source": [
    "**TODO:** Define a model with no hidden layers. This model should just be a linear layer that maps from the input dimension, `D_i` to the output dimension, `D_o`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1721939029187,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "OpKrzL2Dw9Gt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2KDpACWxJ43"
   },
   "source": [
    "**TODO**: Train the model using the same code as above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "88LzTORexQfX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnmXf9ZVxUum"
   },
   "source": [
    "**TODO**: Plot the results using the same code as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4w2DbeqWyNDr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GhYWl39Hn2kx"
   },
   "source": [
    "### Part 1.d: Discussion\n",
    "What did you observe as you changed the model capacity in your experiments? What are some measures you might include to improve generalization of your models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_qzCupZxv56"
   },
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWdgJdgGy163"
   },
   "source": [
    "## Q2:  Bias-variance Trade-off\n",
    "\n",
    "In this problem, we will investigate the bias-variance trade-off and reproduce the curves seen in Figure 8.8 in Prince."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1721939033578,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "biNd-0BmzB8S"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FyyvXug7zSJT"
   },
   "source": [
    "Let's specify the true function that we are trying to estimate, defined on [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1721939033578,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "dp_hhiFHzN1j"
   },
   "outputs": [],
   "source": [
    "def true_function(x):\n",
    "    y = np.exp(np.sin(x*(2*3.1413)))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTz8KoI9zV20"
   },
   "source": [
    "Now let's generate some data point and add bit of noise to the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1721939033578,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "RibUkvvBzUkC"
   },
   "outputs": [],
   "source": [
    "def generate_data(n_data, sigma_y=0.3):\n",
    "    # Generate x values quasi uniformly\n",
    "    x = np.ones(n_data)\n",
    "    for i in range(n_data):\n",
    "        x[i] = np.random.uniform(i/n_data, (i+1)/n_data, 1)\n",
    "\n",
    "    # y value from running through function and adding noise\n",
    "    y = np.ones(n_data)\n",
    "    for i in range(n_data):\n",
    "        y[i] = true_function(x[i])\n",
    "        y[i] += np.random.normal(0, sigma_y, 1)\n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tc-ywywAzf6O"
   },
   "source": [
    "Let's draw the fitted function, together with uncertainty used to generate points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1721939033578,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "pIPVYxWEzfJ5"
   },
   "outputs": [],
   "source": [
    "def plot_function(x_func, y_func, x_data=None,y_data=None, x_model = None, y_model =None, sigma_func = None, sigma_model=None):\n",
    "\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.plot(x_func, y_func, 'k-')\n",
    "    if sigma_func is not None:\n",
    "      ax.fill_between(x_func, y_func-2*sigma_func, y_func+2*sigma_func, color='lightgray')\n",
    "\n",
    "    if x_data is not None:\n",
    "        ax.plot(x_data, y_data, 'o', color='#d18362')\n",
    "\n",
    "    if x_model is not None:\n",
    "        ax.plot(x_model, y_model, '-', color='#7fe7de')\n",
    "\n",
    "    if sigma_model is not None:\n",
    "      ax.fill_between(x_model, y_model-2*sigma_model, y_model+2*sigma_model, color='lightgray')\n",
    "\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_xlabel('Input, x')\n",
    "    ax.set_ylabel('Output, y')\n",
    "    plt.show()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p14Ig5cNzxru"
   },
   "source": [
    "Sample from the true function (no noise):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1721939033578,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "pMBVcLwNzjmn"
   },
   "outputs": [],
   "source": [
    "x_func = np.linspace(0, 1.0, 100)\n",
    "y_func = true_function(x_func);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UyzfDRwz5e1"
   },
   "source": [
    "Generate some training data (with noise):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1721939033578,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "LqnTSqluz-am",
    "outputId": "54555407-fc70-4273-9013-531c81d026b5"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "sigma_func = 0.3\n",
    "n_data = 15\n",
    "x_data,y_data = generate_data(n_data, sigma_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3wH2zDi0H5s"
   },
   "source": [
    "Plot the data with the functions defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 420,
     "status": "ok",
     "timestamp": 1721939033996,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "_GBGX5K60Lbz",
    "outputId": "f485ce6c-7d7a-4896-cfd1-e1e858b51f30"
   },
   "outputs": [],
   "source": [
    "plot_function(x_func, y_func, x_data, y_data, sigma_func=sigma_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1721939033996,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "t8SVgFH50MMs"
   },
   "outputs": [],
   "source": [
    "# Define model -- beta is a scalar and omega has size n_hidden,1\n",
    "def network(x, beta, omega):\n",
    "    # Retrieve number of hidden units\n",
    "    n_hidden = omega.shape[0]\n",
    "\n",
    "    y = np.zeros_like(x)\n",
    "    for c_hidden in range(n_hidden):\n",
    "        # Evaluate activations based on shifted lines (figure 8.4b-d)\n",
    "        line_vals =  x  - c_hidden/n_hidden\n",
    "        h =  line_vals * (line_vals > 0)\n",
    "        # Weight activations by omega parameters and sum\n",
    "        y = y + omega[c_hidden] * h\n",
    "    # Add bias, beta\n",
    "    y = y + beta\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1721939033996,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "9A3Hwp462OcD"
   },
   "outputs": [],
   "source": [
    "# This fits the n_hidden+1 parameters (see fig 8.4a) in closed form.\n",
    "# If you have studied linear algebra, then you will know it is a least\n",
    "# squares solution of the form (A^TA)^-1A^Tb.  If you don't recognize that,\n",
    "# then just take it on trust that this gives you the best possible solution.\n",
    "def fit_model_closed_form(x,y,n_hidden):\n",
    "  n_data = len(x)\n",
    "  A = np.ones((n_data, n_hidden+1))\n",
    "  for i in range(n_data):\n",
    "      for j in range(1,n_hidden+1):\n",
    "          A[i,j] = x[i]-(j-1)/n_hidden\n",
    "          if A[i,j] < 0:\n",
    "              A[i,j] = 0;\n",
    "\n",
    "  beta_omega = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "\n",
    "  beta = beta_omega[0]\n",
    "  omega = beta_omega[1:]\n",
    "\n",
    "  return beta, omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 173,
     "status": "ok",
     "timestamp": 1721939034167,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "d0pMEIav2SkA",
    "outputId": "619e9051-b654-465a-8016-ca96dabace42"
   },
   "outputs": [],
   "source": [
    "# Closed form solution\n",
    "beta, omega = fit_model_closed_form(x_data,y_data,n_hidden=3)\n",
    "\n",
    "# Get prediction for model across graph range\n",
    "x_model = np.linspace(0,1,100);\n",
    "y_model = network(x_model, beta, omega)\n",
    "\n",
    "# Draw the function and the model\n",
    "plot_function(x_func, y_func, x_data,y_data, x_model, y_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lo9GjQKLftvu"
   },
   "source": [
    "### Part 2.a) Estimating the mean and variance of the model outputs, over many training runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6m0EzZa28Nl"
   },
   "source": [
    "**TODO:** Fill in the missing pieces of this function to tun the model many times with different datasets and return the mean and variance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1721939034167,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "lTSCIXEi2YqR"
   },
   "outputs": [],
   "source": [
    "def get_model_mean_variance(n_data, n_datasets, n_hidden, sigma_func):\n",
    "\n",
    "  # Create array that stores model results in rows\n",
    "  y_model_all = np.zeros((n_datasets, n_data))\n",
    "\n",
    "  for c_dataset in range(n_datasets):\n",
    "    # TODO -- Generate n_data x,y, pairs with standard deviation sigma_func\n",
    "    # Replace this line\n",
    "    x_data, y_data = None, None\n",
    "\n",
    "    # TODO -- Fit the model\n",
    "    # Replace this line:\n",
    "    beta, omega = None, None\n",
    "\n",
    "    # TODO -- Run the fitted model on x_model\n",
    "    # Replace this line\n",
    "    y_model = None\n",
    "\n",
    "    # Store the model results\n",
    "    y_model_all[c_dataset,:] = y_model\n",
    "\n",
    "  # Get mean and standard deviation of model\n",
    "  mean_model = np.mean(y_model_all,axis=0)\n",
    "  std_model = np.std(y_model_all,axis=0)\n",
    "\n",
    "  # Return the mean and standard deviation of the fitted model\n",
    "  return mean_model, std_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzMkq7KrfVpf"
   },
   "source": [
    "Let's generate N=100 random data sets, fit the model N=100 times and look the mean and variance. Here we will have 15 data points and 3 hidden units in our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1721939034167,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "SVA-Fsek2awb",
    "outputId": "9773f406-38f3-403b-98ff-da8ba199ffc5"
   },
   "outputs": [],
   "source": [
    "n_datasets = 100\n",
    "n_data = 15\n",
    "sigma_func = 0.3\n",
    "n_hidden = 3\n",
    "\n",
    "# Get mean and variance of fitted model\n",
    "np.random.seed(1)\n",
    "mean_model, std_model = get_model_mean_variance(n_data, n_datasets, n_hidden, sigma_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKXyiLhufnKy"
   },
   "source": [
    "Plot the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1721939034478,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "Z_sVRJFM59Il",
    "outputId": "8e185411-d057-419d-a227-a92acb37adab"
   },
   "outputs": [],
   "source": [
    "x_model_grid = np.linspace(0, 1, len(mean_model))\n",
    "plot_function(x_func, y_func, x_model=x_model_grid, y_model=mean_model, sigma_model=std_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eh4WZfS1eLCf"
   },
   "source": [
    "If you did this correctly, you can see that there that we observe both **bias** and **variance** in the model outputs. Here bias refers to the fact that we have some error from the model outputs and the true function (distance between cyan and black lines); variance refers to the gray region indicating there is a fair amount of variability in what the model outputs over each dataset it sees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HwK2BJaTgfEf"
   },
   "source": [
    "### Part 2.b) Changing the amount of available data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fmgb8vk9gkmq"
   },
   "source": [
    "**TODO**: Let's rerun the same experiment as the cell above, but this time let's increase the the number of training points to 100, `n_data=100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 131,
     "status": "ok",
     "timestamp": 1721939384088,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "TocjrVyMgjv-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CfwYl0RFg5RB"
   },
   "source": [
    "**TODO**: Plot the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 232,
     "status": "ok",
     "timestamp": 1721939388329,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "C22lkN1Fg6vN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQ85NPNJhErP"
   },
   "source": [
    "**TODO**: What happened to the variance? Record your observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ILpVwLAchNIE"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZbtyZAdhU3n"
   },
   "source": [
    "### Part 2.c) Increasing the model capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PELiw9OmhgZI"
   },
   "source": [
    "**TODO**: Let's rerun the same experiment as the cell above, but this time let's increase set the number of hidden units to 12 and the number of training points to 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 149,
     "status": "ok",
     "timestamp": 1721939398242,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "qzObr8GtiHAC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HinKPGgQiQjd"
   },
   "source": [
    "**TODO**: Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1721939400552,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "2Qr9NuZFiUab"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ddt1HRY8iXSa"
   },
   "source": [
    "**TODO**: What happened to the bias? Record your observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "STzzHzUXibS9"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-q3uKaPibZd"
   },
   "source": [
    "### Part 1d) High capacity and high data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0ADRLw4i4cO"
   },
   "source": [
    "**TODO**: Let's rerun the same experiment as the cell above, but this time let's increase set the number of hidden units to 12 and the number of training points to 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 143,
     "status": "ok",
     "timestamp": 1721939413430,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "6EWpipC2i72U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7AJjSURi-Qx"
   },
   "source": [
    "**TODO:** Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 132,
     "status": "ok",
     "timestamp": 1721939427100,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "TwFGSKRIjHgd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdwDgFvrjFjV"
   },
   "source": [
    "**TODO**: Record your observations about the bias and variance in this setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7z1Hf1QJjQKg"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Ce1iSIwamXh"
   },
   "source": [
    "## Q3) High Dimensional Spaces\n",
    "This question investigates the strange properties of high-dimensional spaces as discussed in the notes at the end of chapter 8.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1721939041255,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "6xfTUNQvcPx-"
   },
   "outputs": [],
   "source": [
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 135,
     "status": "ok",
     "timestamp": 1721939041388,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "XRRwkYqVan88"
   },
   "outputs": [],
   "source": [
    "# Fix the random seed so we all have the same random numbers\n",
    "np.random.seed(0)\n",
    "n_data = 1000\n",
    "# Create 1000 data examples (columns) each with 2 dimensions (rows)\n",
    "n_dim = 2\n",
    "x_2D = np.random.normal(size=(n_dim,n_data))\n",
    "# Create 1000 data examples (columns) each with 100 dimensions (rows)\n",
    "n_dim = 100\n",
    "x_100D = np.random.normal(size=(n_dim,n_data))\n",
    "# Create 1000 data examples (columns) each with 1000 dimensions (rows)\n",
    "n_dim = 1000\n",
    "x_1000D = np.random.normal(size=(n_dim,n_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HlY5Ewr9d9Kd"
   },
   "source": [
    "**TODO:** Implement the missing parts of the function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 138,
     "status": "ok",
     "timestamp": 1721939452661,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "hRrYxiAIaxHp"
   },
   "outputs": [],
   "source": [
    "def distance_ratio(x):\n",
    "  # TODO -- replace the two lines below to calculate the largest and smallest Euclidean distance between\n",
    "  # the data points in the columns of x.  DO NOT include the distance between the data point\n",
    "  # and itself (which is obviously zero)\n",
    "\n",
    "  smallest_dist = 1.0\n",
    "  largest_dist = 1.0\n",
    "\n",
    "  # Calculate the ratio and return\n",
    "  dist_ratio = largest_dist / smallest_dist\n",
    "  return dist_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 177,
     "status": "ok",
     "timestamp": 1721939454503,
     "user": {
      "displayName": "Porter Jenkins",
      "userId": "02898551491497513068"
     },
     "user_tz": 360
    },
    "id": "of_ivtxgayPp",
    "outputId": "0b9dd7d1-e5bc-4d6b-b87a-8a4c3bc4b261"
   },
   "outputs": [],
   "source": [
    "\n",
    "print('Ratio of largest to smallest distance 2D: %3.3f'%(distance_ratio(x_2D)))\n",
    "print('Ratio of largest to smallest distance 100D: %3.3f'%(distance_ratio(x_100D)))\n",
    "print('Ratio of largest to smallest distance 1000D: %3.3f'%(distance_ratio(x_1000D)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wKlKDJ5ld0HT"
   },
   "source": [
    "If you did this right, you will see that the distance between the nearest and farthest two points in high dimensions is almost the same.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmyrvE3Ljzt7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMTKyxP874IvwqjA6jyCJ8e",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
